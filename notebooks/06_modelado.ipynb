{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 06 - Modelado Predictivo de Exceso Epidemico\n",
    "\n",
    "**Proyecto:** EDA de Dengue en Colombia  \n",
    "**Maestria en Inteligencia Artificial** - Desarrollo de Soluciones  \n",
    "\n",
    "Este notebook entrena modelos de clasificacion para predecir si un municipio experimentara **exceso epidemico** de dengue en un mes dado, utilizando:\n",
    "- Variables climaticas y sus rezagos temporales\n",
    "- Indicadores epidemiologicos (proporciones, tasas)\n",
    "- Datos demograficos y poblacionales\n",
    "\n",
    "**Modelos:** Logistic Regression, Random Forest, XGBoost  \n",
    "**Datos:** `data/processed/panel_municipal_mensual.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    f1_score, precision_score, recall_score, accuracy_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "from utils import configurar_estilo, PROJECT_ROOT\n",
    "\n",
    "configurar_estilo()\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print('Librerias cargadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Carga y preparacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar panel municipal-mensual\n",
    "data_path = PROJECT_ROOT / 'data' / 'processed' / 'panel_municipal_mensual.parquet'\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(f'Dimensiones: {df.shape[0]:,} filas x {df.shape[1]} columnas')\n",
    "print(f'\\nColumnas ({len(df.columns)}):')\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f'  {i+1:2d}. {col} ({df[col].dtype})', end='\\n')\n",
    "\n",
    "print(f'\\nAnos disponibles: {sorted(df[\"ano\"].unique())}')\n",
    "print(f'Municipios unicos: {df[\"cod_mun_n_str\"].nunique()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Balance de la variable objetivo `exceso`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts y porcentajes\n",
    "print('Distribucion de la variable objetivo `exceso`:')\n",
    "print(df['exceso'].value_counts())\n",
    "print(f'\\nPorcentajes:')\n",
    "print(df['exceso'].value_counts(normalize=True).mul(100).round(2))\n",
    "\n",
    "ratio = df['exceso'].value_counts()[0] / df['exceso'].value_counts()[1]\n",
    "print(f'\\nRatio clase mayoritaria / minoritaria: {ratio:.1f}:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Grafico de barras del balance global\n",
    "counts = df['exceso'].value_counts()\n",
    "bars = axes[0].bar(['Sin exceso (0)', 'Con exceso (1)'], counts.values,\n",
    "                    color=['#2196F3', '#F44336'], edgecolor='white')\n",
    "for bar, val in zip(bars, counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200,\n",
    "                 f'{val:,}\\n({val/len(df)*100:.1f}%)',\n",
    "                 ha='center', va='bottom', fontweight='bold')\n",
    "axes[0].set_title('Balance de la variable objetivo', fontweight='bold')\n",
    "axes[0].set_ylabel('Numero de observaciones')\n",
    "\n",
    "# Balance por ano\n",
    "balance_ano = df.groupby('ano')['exceso'].mean().mul(100)\n",
    "bars2 = axes[1].bar(balance_ano.index.astype(str), balance_ano.values,\n",
    "                     color='#F44336', edgecolor='white', alpha=0.8)\n",
    "for bar, val in zip(bars2, balance_ano.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,\n",
    "                 f'{val:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "axes[1].set_title('Porcentaje de exceso epidemico por ano', fontweight='bold')\n",
    "axes[1].set_ylabel('% municipios-mes con exceso')\n",
    "axes[1].set_xlabel('Ano')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Conclusion: La variable objetivo esta muy desbalanceada (~5.3% positivo).')\n",
    "print('Se usaran tecnicas de manejo de desbalance: class_weight=\"balanced\" y scale_pos_weight.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Seleccion de features y target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir features\n",
    "# Clima actuales\n",
    "feats_clima = ['temperatura_c', 'precipitacion_mm', 'ndvi', 'dewpoint_c']\n",
    "\n",
    "# Lags climaticos (1-3 meses)\n",
    "feats_clima_lags = [f'{v}_lag{l}' for v in feats_clima for l in [1, 2, 3]]\n",
    "\n",
    "# Medias moviles climaticas\n",
    "feats_clima_mm = [f'{v}_mm3' for v in feats_clima]\n",
    "\n",
    "# Lags de casos y tasa\n",
    "feats_epi_lags = [\n",
    "    'casos_total_lag1', 'casos_total_lag2', 'casos_total_lag3',\n",
    "    'tasa_incidencia_lag1', 'tasa_incidencia_lag2', 'tasa_incidencia_lag3',\n",
    "]\n",
    "\n",
    "# Medias moviles epidemiologicas\n",
    "feats_epi_mm = ['casos_total_mm3', 'tasa_incidencia_mm3']\n",
    "\n",
    "# Demograficos y poblacion\n",
    "feats_demo = ['prop_grave', 'prop_hospitalizado', 'prop_femenino', 'poblacion']\n",
    "\n",
    "# Concatenar todos los features\n",
    "FEATURES = feats_clima + feats_clima_lags + feats_clima_mm + feats_epi_lags + feats_epi_mm + feats_demo\n",
    "TARGET = 'exceso'\n",
    "\n",
    "print(f'Total features seleccionados: {len(FEATURES)}')\n",
    "print(f'\\nFeatures climaticos actuales ({len(feats_clima)}): {feats_clima}')\n",
    "print(f'Features climaticos lags ({len(feats_clima_lags)}): {feats_clima_lags}')\n",
    "print(f'Features climaticos mm3 ({len(feats_clima_mm)}): {feats_clima_mm}')\n",
    "print(f'Features epidemiologicos lags ({len(feats_epi_lags)}): {feats_epi_lags}')\n",
    "print(f'Features epidemiologicos mm3 ({len(feats_epi_mm)}): {feats_epi_mm}')\n",
    "print(f'Features demograficos ({len(feats_demo)}): {feats_demo}')\n",
    "print(f'\\nTarget: {TARGET}')\n",
    "\n",
    "# Variables excluidas intencionalmente\n",
    "excluidas = [\n",
    "    'cod_dpto_n_str', 'cod_mun_n_str', 'Departamento_Notificacion',\n",
    "    'Municipio_notificacion', 'ano', 'mes',\n",
    "    'casos_total', 'casos_regular', 'casos_grave',\n",
    "    'hospitalizaciones', 'fallecidos', 'edad_media',\n",
    "    'n_femenino', 'n_masculino', 'tasa_incidencia',\n",
    "    'media_hist', 'std_hist', 'umbral_exceso',\n",
    "    'media_tasa_hist', 'std_tasa_hist', 'umbral_exceso_tasa',\n",
    "    'exceso', 'exceso_tasa'\n",
    "]\n",
    "print(f'\\nVariables excluidas ({len(excluidas)}): IDs, conteos directos, estadisticas historicas, targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dataset: dropear filas con NaN en features (lags de enero generan NaN)\n",
    "df_model = df[FEATURES + [TARGET, 'ano']].copy()\n",
    "\n",
    "print(f'Antes de dropear NaN: {len(df_model):,} filas')\n",
    "print(f'\\nNaN por feature:')\n",
    "nans = df_model[FEATURES].isnull().sum()\n",
    "nans_pct = (nans / len(df_model) * 100).round(1)\n",
    "nan_df = pd.DataFrame({'nulos': nans, 'pct': nans_pct})\n",
    "print(nan_df[nan_df['nulos'] > 0].to_string())\n",
    "\n",
    "df_model = df_model.dropna(subset=FEATURES)\n",
    "print(f'\\nDespues de dropear NaN: {len(df_model):,} filas ({len(df_model)/len(df)*100:.1f}% del total)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Split temporal train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporal: Train = 2010, 2016, 2019, 2022 | Test = 2024\n",
    "anos_train = [2010, 2016, 2019, 2022]\n",
    "anos_test = [2024]\n",
    "\n",
    "train_mask = df_model['ano'].isin(anos_train)\n",
    "test_mask = df_model['ano'].isin(anos_test)\n",
    "\n",
    "X_train = df_model.loc[train_mask, FEATURES]\n",
    "y_train = df_model.loc[train_mask, TARGET]\n",
    "X_test = df_model.loc[test_mask, FEATURES]\n",
    "y_test = df_model.loc[test_mask, TARGET]\n",
    "\n",
    "print(f'Split temporal:')\n",
    "print(f'  Train ({anos_train}): {len(X_train):,} filas')\n",
    "print(f'  Test  ({anos_test}):  {len(X_test):,} filas')\n",
    "print(f'\\nBalance en Train:')\n",
    "print(f'  Clase 0: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.1f}%)')\n",
    "print(f'  Clase 1: {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.1f}%)')\n",
    "print(f'\\nBalance en Test:')\n",
    "print(f'  Clase 0: {(y_test == 0).sum():,} ({(y_test == 0).mean()*100:.1f}%)')\n",
    "print(f'  Clase 1: {(y_test == 1).sum():,} ({(y_test == 1).mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Modelo 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar features para Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar modelo\n",
    "lr = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_prob_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Metricas\n",
    "print('=== Logistic Regression ===')\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Sin exceso', 'Con exceso']))\n",
    "\n",
    "roc_auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "print(f'ROC-AUC: {roc_auc_lr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Sin exceso', 'Con exceso'],\n",
    "            yticklabels=['Sin exceso', 'Con exceso'])\n",
    "axes[0].set_title('Matriz de Confusion - Logistic Regression', fontweight='bold')\n",
    "axes[0].set_ylabel('Real')\n",
    "axes[0].set_xlabel('Predicho')\n",
    "\n",
    "# Curva ROC\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)\n",
    "axes[1].plot(fpr_lr, tpr_lr, color='#2196F3', lw=2,\n",
    "             label=f'Logistic Regression (AUC = {roc_auc_lr:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Curva ROC - Logistic Regression', fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo (no requiere escalado)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metricas\n",
    "print('=== Random Forest ===')\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Sin exceso', 'Con exceso']))\n",
    "\n",
    "roc_auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "print(f'ROC-AUC: {roc_auc_rf:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[0],\n",
    "            xticklabels=['Sin exceso', 'Con exceso'],\n",
    "            yticklabels=['Sin exceso', 'Con exceso'])\n",
    "axes[0].set_title('Matriz de Confusion - Random Forest', fontweight='bold')\n",
    "axes[0].set_ylabel('Real')\n",
    "axes[0].set_xlabel('Predicho')\n",
    "\n",
    "# Curva ROC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "axes[1].plot(fpr_rf, tpr_rf, color='#4CAF50', lw=2,\n",
    "             label=f'Random Forest (AUC = {roc_auc_rf:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Curva ROC - Random Forest', fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "# Feature Importance Top 15\n",
    "importances = pd.Series(rf.feature_importances_, index=FEATURES)\n",
    "top15_rf = importances.nlargest(15)\n",
    "top15_rf.sort_values().plot(kind='barh', ax=axes[2], color='#4CAF50', edgecolor='white')\n",
    "axes[2].set_title('Top 15 Features - Random Forest', fontweight='bold')\n",
    "axes[2].set_xlabel('Importancia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. Modelo 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular scale_pos_weight para desbalance\n",
    "n_neg = (y_train == 0).sum()\n",
    "n_pos = (y_train == 1).sum()\n",
    "spw = n_neg / n_pos\n",
    "print(f'scale_pos_weight = {n_neg}/{n_pos} = {spw:.2f}')\n",
    "\n",
    "# Entrenar modelo\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=spw,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metricas\n",
    "print('\\n=== XGBoost ===')\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['Sin exceso', 'Con exceso']))\n",
    "\n",
    "roc_auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "print(f'ROC-AUC: {roc_auc_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Oranges', ax=axes[0],\n",
    "            xticklabels=['Sin exceso', 'Con exceso'],\n",
    "            yticklabels=['Sin exceso', 'Con exceso'])\n",
    "axes[0].set_title('Matriz de Confusion - XGBoost', fontweight='bold')\n",
    "axes[0].set_ylabel('Real')\n",
    "axes[0].set_xlabel('Predicho')\n",
    "\n",
    "# Curva ROC\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "axes[1].plot(fpr_xgb, tpr_xgb, color='#FF9800', lw=2,\n",
    "             label=f'XGBoost (AUC = {roc_auc_xgb:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Curva ROC - XGBoost', fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "# Feature Importance Top 15\n",
    "importances_xgb = pd.Series(xgb.feature_importances_, index=FEATURES)\n",
    "top15_xgb = importances_xgb.nlargest(15)\n",
    "top15_xgb.sort_values().plot(kind='barh', ax=axes[2], color='#FF9800', edgecolor='white')\n",
    "axes[2].set_title('Top 15 Features - XGBoost', fontweight='bold')\n",
    "axes[2].set_xlabel('Importancia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 8. Comparacion de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla resumen de metricas\n",
    "modelos = {\n",
    "    'Logistic Regression': (y_pred_lr, y_prob_lr),\n",
    "    'Random Forest': (y_pred_rf, y_prob_rf),\n",
    "    'XGBoost': (y_pred_xgb, y_prob_xgb),\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "for nombre, (y_pred, y_prob) in modelos.items():\n",
    "    resultados.append({\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision (exceso)': precision_score(y_test, y_pred),\n",
    "        'Recall (exceso)': recall_score(y_test, y_pred),\n",
    "        'F1-Score (exceso)': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_prob),\n",
    "    })\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).set_index('Modelo')\n",
    "print('=== Comparacion de Modelos (Test 2024) ===')\n",
    "print(df_resultados.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Grafico comparativo de metricas\n",
    "metricas_plot = df_resultados[['F1-Score (exceso)', 'ROC-AUC', 'Recall (exceso)', 'Precision (exceso)']]\n",
    "metricas_plot.plot(kind='bar', ax=axes[0], edgecolor='white', width=0.7)\n",
    "axes[0].set_title('Comparacion de Metricas por Modelo', fontweight='bold')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].legend(loc='upper left', fontsize=9)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Curvas ROC comparativas\n",
    "axes[1].plot(fpr_lr, tpr_lr, color='#2196F3', lw=2,\n",
    "             label=f'Logistic Regression (AUC={roc_auc_lr:.4f})')\n",
    "axes[1].plot(fpr_rf, tpr_rf, color='#4CAF50', lw=2,\n",
    "             label=f'Random Forest (AUC={roc_auc_rf:.4f})')\n",
    "axes[1].plot(fpr_xgb, tpr_xgb, color='#FF9800', lw=2,\n",
    "             label=f'XGBoost (AUC={roc_auc_xgb:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.5)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('Curvas ROC Comparativas', fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusiones\n",
    "mejor_f1 = df_resultados['F1-Score (exceso)'].idxmax()\n",
    "mejor_auc = df_resultados['ROC-AUC'].idxmax()\n",
    "\n",
    "print('=' * 60)\n",
    "print('CONCLUSIONES')\n",
    "print('=' * 60)\n",
    "print(f'\\n1. Mejor modelo por F1-Score: {mejor_f1} ({df_resultados.loc[mejor_f1, \"F1-Score (exceso)\"]:.4f})')\n",
    "print(f'2. Mejor modelo por ROC-AUC:  {mejor_auc} ({df_resultados.loc[mejor_auc, \"ROC-AUC\"]:.4f})')\n",
    "print(f'\\n3. El dataset esta altamente desbalanceado (~5% positivo),')\n",
    "print(f'   por lo que las tecnicas de class_weight/scale_pos_weight')\n",
    "print(f'   son fundamentales para obtener recall aceptable en la clase minoritaria.')\n",
    "print(f'\\n4. Las metricas principales son F1-Score y ROC-AUC,')\n",
    "print(f'   ya que accuracy no es informativa con clases tan desbalanceadas.')\n",
    "print(f'\\n5. Resumen de metricas finales:')\n",
    "print(df_resultados[['F1-Score (exceso)', 'ROC-AUC']].round(4).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}